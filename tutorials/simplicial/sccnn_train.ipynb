{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a SCCNN\n",
    "\n",
    "In this notebook, we will create and train a convolutional neural network in the simplicial complex domain, as proposed in the paper by [Yang et. al : Convolutional Learning on Simplicial Complexes (2023)](https://arxiv.org/abs/2301.11163). \n",
    "\n",
    "### We train the model to perform:\n",
    "    1.  Complex classification using the shrec16 benchmark dataset.\n",
    "    2.  Node classification using the karate dataset \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplicial Complex Convolutional Neural Networks <a href=\"https://arxiv.org/pdf/2301.11163.pdf\">[SCCNN]</a>\n",
    "\n",
    "SCCNN extends the SCNN to the complex domain by accounting for inter-simplicial connections, i.e., contributions from simplices of adjacent orders. \n",
    "\n",
    "For example, we consider SCCNN layers in an SC of order two. At layer $t$, given the inputs on nodes, edges and faces, $\\mathbf{h}_{t}^0,\\mathbf{h}_{t}^1$ and $\\mathbf{h}_{t}^2$, the SCCNN layer contains the following\n",
    "$$\n",
    "    \\mathbf{h}_{t+1}^1 = \\sigma \\bigg[ \\mathbf{F}_{t,\\downarrow} \\mathbf{B}_{1}^\\top \\mathbf{h}_{t}^{0} + \\mathbf{F}_{t} \\mathbf{h}_t^1 + \\mathbf{F}_{t,\\uparrow} \\mathbf{B}_{2}  \\mathbf{h}_t^{2} \\bigg] \n",
    "$$\n",
    "where $\\mathbf{F}_t$ is the simplicial convolutional filter defined in the edge space, and $\\mathbf{F}_{t,\\downarrow}$ and $\\mathbf{F}_{t,\\uparrow}$ are the convolutional filters based on, respectively, only the lower and upper Laplacians. They are given by \n",
    "$$\n",
    "    \\mathbf{F}_{t} = {\\theta}_t + \\sum_{p_d=1}^{P_d} {\\theta}_{t,p_d} (\\mathbf{L}_{\\downarrow,1})^{p_d}  + \\sum_{p_u=1}^{P_u} {\\theta}_{t,p_u}  (\\mathbf{L}_{\\uparrow,1})^{p_u} \n",
    "$$\n",
    "$$\n",
    "    \\mathbf{F}_{t,\\downarrow} = {\\theta}_t + \\sum_{p_d=1}^{P_d} {\\theta}_{t,p_d} (\\mathbf{L}_{\\downarrow,1})^{p_d}  \n",
    "    \\text{ and } \n",
    "    \\mathbf{F}_{t,\\uparrow} = {\\theta}_t + \\sum_{p_u=1}^{P_u} {\\theta}_{t,p_u}  (\\mathbf{L}_{\\uparrow,1})^{p_u} \n",
    "$$\n",
    "\n",
    "Likewise, for the node output, we have \n",
    "$$\n",
    "    \\mathbf{h}_{t+1}^0 = \\sigma \\bigg[ \\mathbf{F}_{t} \\mathbf{h}_t^0 + \\mathbf{F}_{t,\\uparrow} \\mathbf{B}_{1}  \\mathbf{h}_t^{1} \\bigg]\n",
    "$$\n",
    "where $\\mathbf{F}_t$ and $\\mathbf{F}_{t,\\uparrow}$ are two graph filters essentially. \n",
    "\n",
    "For the face output, we have \n",
    "$$\n",
    "    \\mathbf{h}_{t+1}^2 = \\sigma \\bigg[ \\mathbf{F}_{t} \\mathbf{h}_{t}^{2}  + \\mathbf{F}_{t,\\downarrow} \\mathbf{B}_{2}^\\top  \\mathbf{h}_t^{1} \\bigg]\n",
    "$$\n",
    "where $\\mathbf{F}_t$ and $\\mathbf{F}_{t,\\downarrow}$ are two simplicial filters defined in the triangle (face) space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Complex Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets as datasets\n",
    "from topomodelx.nn.simplicial.sccnn_layer import SCCNNLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "### Import shrec dataset ##\n",
    "\n",
    "We must first lift our graph dataset into the simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10, 7)\n"
     ]
    }
   ],
   "source": [
    "in_channels_0 = x_0s[-1].shape[1]\n",
    "in_channels_1 = x_1s[-1].shape[1]\n",
    "in_channels_2 = x_2s[-1].shape[1]\n",
    "\n",
    "in_channels_all = (in_channels_0, in_channels_1, in_channels_2)\n",
    "print(in_channels_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neighborhood Strctures\n",
    "Get incidence matrices $\\mathbf{B}_1,\\mathbf{B}_2$ and Hodge Laplacians $\\mathbf{L}_0, \\mathbf{L}_1$ and $\\mathbf{L}_2$.\n",
    "\n",
    "Note that the original paper considered the weighted versions of these operators. However, the current TOPONETX package does not provide such feature yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank = 2  # the order of the SC is two\n",
    "incidence_1_list = []\n",
    "incidence_2_list = []\n",
    "\n",
    "laplacian_0_list = []\n",
    "laplacian_down_1_list = []\n",
    "laplacian_up_1_list = []\n",
    "laplacian_2_list = []\n",
    "\n",
    "for simplex in simplexes:\n",
    "    incidence_1 = simplex.incidence_matrix(rank=1)\n",
    "    incidence_2 = simplex.incidence_matrix(rank=2)\n",
    "    laplacian_0 = simplex.hodge_laplacian_matrix(rank=0, weight=True)\n",
    "    laplacian_down_1 = simplex.down_laplacian_matrix(rank=1, weight=True)\n",
    "    laplacian_up_1 = simplex.up_laplacian_matrix(rank=1, weight=True)\n",
    "    laplacian_2 = simplex.hodge_laplacian_matrix(rank=2, weight=True)\n",
    "\n",
    "    incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "    incidence_2 = torch.from_numpy(incidence_2.todense()).to_sparse()\n",
    "    laplacian_0 = torch.from_numpy(laplacian_0.todense()).to_sparse()\n",
    "    laplacian_down_1 = torch.from_numpy(laplacian_down_1.todense()).to_sparse()\n",
    "    laplacian_up_1 = torch.from_numpy(laplacian_up_1.todense()).to_sparse()\n",
    "    laplacian_2 = torch.from_numpy(laplacian_2.todense()).to_sparse()\n",
    "\n",
    "    incidence_1_list.append(incidence_1)\n",
    "    incidence_2_list.append(incidence_2)\n",
    "    laplacian_0_list.append(laplacian_0)\n",
    "    laplacian_down_1_list.append(laplacian_down_1)\n",
    "    laplacian_up_1_list.append(laplacian_up_1)\n",
    "    laplacian_2_list.append(laplacian_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SCCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCCNN(torch.nn.Module):\n",
    "    \"\"\"SCCNN implementation for complex classification\n",
    "    Note: In this task, we can consider the output on any order of simplices for the classification task, which of course can be amended by a readout layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels_all: tuple of int\n",
    "        Dimension of input features on (nodes, edges, faces)\n",
    "    intermediate_channels_all: tuple of int\n",
    "        Dimension of features of intermediate layers on (nodes, edges, faces)\n",
    "    out_channels_all: tuple of int\n",
    "        Dimension of output features on (nodes, edges, faces)\n",
    "    conv_order: int\n",
    "        Order of convolutions, we consider the same order for all convolutions\n",
    "    sc_order: int\n",
    "        SC order\n",
    "    n_layers: int\n",
    "        Numer of layers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_all,\n",
    "        intermediate_channels_all,\n",
    "        out_channels_all,\n",
    "        conv_order,\n",
    "        sc_order,\n",
    "        aggr_norm=False,\n",
    "        update_func=None,\n",
    "        num_classes=1,\n",
    "        n_layers=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # first layer\n",
    "        # we use an MLP to map the features on simplices of different dimensions to the same dimension\n",
    "        self.in_linear_0 = torch.nn.Linear(\n",
    "            in_channels_all[0], intermediate_channels_all[0]\n",
    "        )\n",
    "        self.in_linear_1 = torch.nn.Linear(\n",
    "            in_channels_all[1], intermediate_channels_all[1]\n",
    "        )\n",
    "        self.in_linear_2 = torch.nn.Linear(\n",
    "            in_channels_all[2], intermediate_channels_all[2]\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                SCCNNLayer(\n",
    "                    in_channels=intermediate_channels_all,\n",
    "                    out_channels=out_channels_all,\n",
    "                    conv_order=conv_order,\n",
    "                    sc_order=sc_order,\n",
    "                    aggr_norm=aggr_norm,\n",
    "                    update_func=update_func,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "        out_channels_0, out_channels_1, out_channels_2 = out_channels_all\n",
    "        self.out_linear_0 = torch.nn.Linear(out_channels_0, num_classes)\n",
    "        self.out_linear_1 = torch.nn.Linear(out_channels_1, num_classes)\n",
    "        self.out_linear_2 = torch.nn.Linear(out_channels_2, num_classes)\n",
    "\n",
    "    def forward(self, x_all, laplacian_all, incidence_all):\n",
    "        \"\"\"Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x: tuple tensors\n",
    "            (node, edge, face) features\n",
    "            each entry shape = [n_simplices, channels]\n",
    "\n",
    "        laplacian: tuple of tensors\n",
    "            (graph laplacian L0, down edge laplacian L1_d, upper edge laplacian L1_u, face laplacian L2)\n",
    "            each entry shape = [n_simplices,n_simplices]\n",
    "\n",
    "        incidence_1: tuple of tensors\n",
    "            tuple pf order 1 and 2 incidence matrices\n",
    "            shape of B1 = [n_nodes, n_edges]\n",
    "            shape of B2 = [n_edges, n_faces]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _ : tensor, shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        x_0, x_1, x_2 = x_all\n",
    "        in_x_0 = self.in_linear_0(x_0)\n",
    "        in_x_1 = self.in_linear_1(x_1)\n",
    "        in_x_2 = self.in_linear_2(x_2)\n",
    "\n",
    "        # Forward through SCCNN\n",
    "        x_all = (in_x_0, in_x_1, in_x_2)\n",
    "        for layer in self.layers:\n",
    "            x_all = layer(x_all, laplacian_all, incidence_all)\n",
    "\n",
    "        \"\"\"\n",
    "        We pass the output on the nodes, edges and triangles to a linear layer and use the sum of the averages of outputs on each simplex for labels of complex\n",
    "        \"\"\"\n",
    "        x_0, x_1, x_2 = x_all\n",
    "\n",
    "        x_0 = self.out_linear_0(x_0)\n",
    "        x_1 = self.out_linear_1(x_1)\n",
    "        x_2 = self.out_linear_2(x_2)\n",
    "\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return (\n",
    "            two_dimensional_cells_mean\n",
    "            + one_dimensional_cells_mean\n",
    "            + zero_dimensional_cells_mean\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCCNN(\n",
      "  (in_linear_0): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (in_linear_1): Linear(in_features=10, out_features=4, bias=True)\n",
      "  (in_linear_2): Linear(in_features=7, out_features=4, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x SCCNNLayer()\n",
      "  )\n",
      "  (out_linear_0): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (out_linear_1): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (out_linear_2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/mmaosheng/.local/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "conv_order = 2\n",
    "intermediate_channels_all = (4, 4, 4)\n",
    "out_channels_all = intermediate_channels_all\n",
    "num_layers = 2\n",
    "\n",
    "model = SCCNN(\n",
    "    in_channels_all=in_channels_all,\n",
    "    intermediate_channels_all=intermediate_channels_all,\n",
    "    out_channels_all=out_channels_all,\n",
    "    conv_order=conv_order,\n",
    "    sc_order=max_rank,\n",
    "    num_classes=1,\n",
    "    n_layers=num_layers,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss(size_average=True, reduction=\"mean\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "x_2_train, x_2_test = train_test_split(x_2s, test_size=test_size, shuffle=False)\n",
    "\n",
    "incidence_1_train, incidence_1_test = train_test_split(\n",
    "    incidence_1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence_2_train, incidence_2_test = train_test_split(\n",
    "    incidence_2_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_0_train, laplacian_0_test = train_test_split(\n",
    "    laplacian_0_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_down_1_train, laplacian_down_1_test = train_test_split(\n",
    "    laplacian_down_1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_up_1_train, laplacian_up_1_test = train_test_split(\n",
    "    laplacian_up_1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "laplacian_2_train, laplacian_2_test = train_test_split(\n",
    "    laplacian_2_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the SCCNN using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/mmaosheng/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/nfs/mmaosheng/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:243: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  if not is_compiling() and torch.has_cuda and torch.cuda.is_available():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 624748.2849\n",
      "Test_loss: 831.5817\n",
      "Epoch: 2 loss: 131.9210\n",
      "Test_loss: 127.5255\n",
      "Epoch: 3 loss: 97.9960\n",
      "Test_loss: 116.0045\n",
      "Epoch: 4 loss: 90.4851\n",
      "Test_loss: 78.6304\n",
      "Epoch: 5 loss: 87.1210\n",
      "Test_loss: 50.7896\n"
     ]
    }
   ],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for (\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        incidence_1,\n",
    "        incidence_2,\n",
    "        laplacian_0,\n",
    "        laplacian_down_1,\n",
    "        laplacian_up_1,\n",
    "        laplacian_2,\n",
    "        y,\n",
    "    ) in zip(\n",
    "        x_0_train,\n",
    "        x_1_train,\n",
    "        x_2_train,\n",
    "        incidence_1_train,\n",
    "        incidence_2_train,\n",
    "        laplacian_0_train,\n",
    "        laplacian_down_1_train,\n",
    "        laplacian_up_1_train,\n",
    "        laplacian_2_train,\n",
    "        y_train,\n",
    "    ):\n",
    "        x_0 = torch.tensor(x_0)\n",
    "        x_1 = torch.tensor(x_1)\n",
    "        x_2 = torch.tensor(x_2)\n",
    "        y = torch.tensor(y, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        x_all = (x_0.float(), x_1.float(), x_2.float())\n",
    "        laplacian_all = (laplacian_0, laplacian_down_1, laplacian_up_1, laplacian_2)\n",
    "        incidence_all = (incidence_1, incidence_2)\n",
    "\n",
    "        y_hat = model(x_all, laplacian_all, incidence_all)\n",
    "\n",
    "        # print(y_hat)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for (\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                incidence_1,\n",
    "                incidence_2,\n",
    "                laplacian_0,\n",
    "                laplacian_down_1,\n",
    "                laplacian_up_1,\n",
    "                laplacian_2,\n",
    "                y,\n",
    "            ) in zip(\n",
    "                x_0_test,\n",
    "                x_1_test,\n",
    "                x_2_test,\n",
    "                incidence_1_test,\n",
    "                incidence_2_test,\n",
    "                laplacian_0_test,\n",
    "                laplacian_down_1_test,\n",
    "                laplacian_up_1_test,\n",
    "                laplacian_2_test,\n",
    "                y_test,\n",
    "            ):\n",
    "                x_0 = torch.tensor(x_0)\n",
    "                x_1 = torch.tensor(x_1)\n",
    "                x_2 = torch.tensor(x_2)\n",
    "                y = torch.tensor(y, dtype=torch.float)\n",
    "                optimizer.zero_grad()\n",
    "                x_all = (x_0.float(), x_1.float(), x_2.float())\n",
    "                laplacian_all = (\n",
    "                    laplacian_0,\n",
    "                    laplacian_down_1,\n",
    "                    laplacian_up_1,\n",
    "                    laplacian_2,\n",
    "                )\n",
    "                incidence_all = (incidence_1, incidence_2)\n",
    "\n",
    "                y_hat = model(x_all, laplacian_all, incidence_all)\n",
    "\n",
    "                loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Node Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "The first step is to import the Karate Club (https://www.jstor.org/stable/3629752) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.\n",
    "\n",
    "We must first lift our graph dataset into the simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = graph.karate_club(complex_type=\"simplicial\")\n",
    "print(dataset)\n",
    "max_rank = dataset.dim\n",
    "print(max_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neighborhood Strctures\n",
    "Get incidence matrices $\\mathbf{B}_1,\\mathbf{B}_2$ and Hodge Laplacians $\\mathbf{L}_0, \\mathbf{L}_1$ and $\\mathbf{L}_2$.\n",
    "\n",
    "Note that the original paper considered the weighted versions of these operators. However, the current TOPONETX package does not provide such feature yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_1 = dataset.incidence_matrix(rank=1)\n",
    "incidence_2 = dataset.incidence_matrix(rank=2)\n",
    "\n",
    "print(f\"The incidence matrix B1 has shape: {incidence_1.shape}.\")\n",
    "print(f\"The incidence matrix B2 has shape: {incidence_2.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_0 = dataset.hodge_laplacian_matrix(rank=0, weight=True)\n",
    "laplacian_down_1 = dataset.down_laplacian_matrix(rank=1, weight=True)\n",
    "laplacian_up_1 = dataset.up_laplacian_matrix(rank=1, weight=True)\n",
    "laplacian_down_2 = dataset.down_laplacian_matrix(rank=2, weight=True)\n",
    "laplacian_up_2 = dataset.up_laplacian_matrix(rank=2, weight=True)\n",
    "\n",
    "laplacian_0 = dataset.adjacency_matrix(rank=0, weight=True)\n",
    "laplacian_down_1 = dataset.coadjacency_matrix(rank=1, weight=True)\n",
    "laplacian_up_1 = dataset.adjacency_matrix(rank=1, weight=True)\n",
    "laplacian_down_2 = dataset.coadjacency_matrix(rank=2, weight=True)\n",
    "laplacian_up_2 = dataset.adjacency_matrix(rank=2, weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_0 = torch.from_numpy(laplacian_0.todense()).to_sparse()\n",
    "laplacian_down_1 = torch.from_numpy(laplacian_down_1.todense()).to_sparse()\n",
    "laplacian_up_1 = torch.from_numpy(laplacian_up_1.todense()).to_sparse()\n",
    "laplacian_down_2 = torch.from_numpy(laplacian_down_2.todense()).to_sparse()\n",
    "laplacian_up_2 = torch.from_numpy(laplacian_up_2.todense()).to_sparse()\n",
    "\n",
    "incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "incidence_2 = torch.from_numpy(incidence_2.todense()).to_sparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import signal ##\n",
    "\n",
    "Since our task will be node classification, we must retrieve an input signal on the nodes. The signal will have shape $n_\\text{nodes} \\times$ in_channels, where in_channels is the dimension of each cell's feature. Here, we have in_channels = channels_nodes $ = 34$. This is because the Karate dataset encodes the identity of each of the 34 nodes as a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A function to obtain features based on the input: rank\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_simplicial_features(dataset, rank):\n",
    "    if rank == 0:\n",
    "        which_feat = \"node_feat\"\n",
    "    elif rank == 1:\n",
    "        which_feat = \"edge_feat\"\n",
    "    elif rank == 2:\n",
    "        which_feat = \"face_feat\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"input dimension must be 0, 1 or 2, because features are supported on nodes, edges and faces\"\n",
    "        )\n",
    "\n",
    "    x = []\n",
    "    for _, v in dataset.get_simplex_attributes(which_feat).items():\n",
    "        x.append(v)\n",
    "\n",
    "    x = torch.tensor(np.stack(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = get_simplicial_features(dataset, rank=0)\n",
    "x_1 = get_simplicial_features(dataset, rank=1)\n",
    "x_2 = get_simplicial_features(dataset, rank=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define binary labels\n",
    "We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.\n",
    "\n",
    "We convert the binary labels into one-hot encoder form, and keep the first four nodes' true labels for the purpose of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "y_true = np.zeros((34, 2))\n",
    "y_true[:, 0] = y\n",
    "y_true[:, 1] = 1 - y\n",
    "y_test = y_true[-4:]\n",
    "y_train = y_true[:30]\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SCCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCCNN(torch.nn.Module):\n",
    "    \"\"\"SCCNN implementation for complex classification\n",
    "    Note: In this task, we can consider the output on any order of simplices for the classification task, which of course can be amended by a readout layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels_all: tuple of int\n",
    "        Dimension of input features on (nodes, edges, faces)\n",
    "    intermediate_channels_all: tuple of int\n",
    "        Dimension of features of intermediate layers on (nodes, edges, faces)\n",
    "    out_channels_all: tuple of int\n",
    "        Dimension of output features on (nodes, edges, faces)\n",
    "    conv_order: int\n",
    "        Order of convolutions, we consider the same order for all convolutions\n",
    "    sc_order: int\n",
    "        SC order\n",
    "    n_layers: int\n",
    "        Numer of layers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_all,\n",
    "        intermediate_channels_all,\n",
    "        out_channels_all,\n",
    "        conv_order,\n",
    "        sc_order,\n",
    "        aggr_norm=False,\n",
    "        update_func=None,\n",
    "        n_layers=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # first layer\n",
    "        # we use an MLP to map the features on simplices of different dimensions to the same dimension\n",
    "        self.in_linear_0 = torch.nn.Linear(\n",
    "            in_channels_all[0], intermediate_channels_all[0]\n",
    "        )\n",
    "        self.in_linear_1 = torch.nn.Linear(\n",
    "            in_channels_all[1], intermediate_channels_all[1]\n",
    "        )\n",
    "        self.in_linear_2 = torch.nn.Linear(\n",
    "            in_channels_all[2], intermediate_channels_all[2]\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                SCCNNLayer(\n",
    "                    in_channels=intermediate_channels_all,\n",
    "                    out_channels=out_channels_all,\n",
    "                    conv_order=conv_order,\n",
    "                    sc_order=sc_order,\n",
    "                    aggr_norm=aggr_norm,\n",
    "                    update_func=update_func,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "        out_channels_0, out_channels_1, out_channels_2 = out_channels_all\n",
    "        self.out_linear_0 = torch.nn.Linear(out_channels_0, 2)\n",
    "\n",
    "    def forward(self, x_all, laplacian_all, incidence_all):\n",
    "        \"\"\"Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x: tuple tensors\n",
    "            (node, edge, face) features\n",
    "            each entry shape = [n_simplices, channels]\n",
    "\n",
    "        laplacian: tuple of tensors\n",
    "            (graph laplacian L0, down edge laplacian L1_d, upper edge laplacian L1_u, face laplacian L2)\n",
    "            each entry shape = [n_simplices,n_simplices]\n",
    "\n",
    "        incidence_1: tuple of tensors\n",
    "            tuple pf order 1 and 2 incidence matrices\n",
    "            shape of B1 = [n_nodes, n_edges]\n",
    "            shape of B2 = [n_edges, n_faces]\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [n_nodes, 2]\n",
    "            One-hot labels assigned to nodes.\n",
    "        \"\"\"\n",
    "        x_0, x_1, x_2 = x_all\n",
    "        in_x_0 = self.in_linear_0(x_0)\n",
    "        in_x_1 = self.in_linear_1(x_1)\n",
    "        in_x_2 = self.in_linear_2(x_2)\n",
    "\n",
    "        # Forward through SCCNN\n",
    "        x_all = (in_x_0, in_x_1, in_x_2)\n",
    "        for layer in self.layers:\n",
    "            x_all = layer(x_all, laplacian_all, incidence_all)\n",
    "\n",
    "        \"\"\"\n",
    "        We pass the output on the nodes to a linear layer and use that to generate a probability label for nodes\n",
    "        \"\"\"\n",
    "        x_0, _, _ = x_all\n",
    "        logits = self.out_linear_0(x_0)\n",
    "        label = torch.sigmoid(logits)\n",
    "\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Obtain the initial features on all simplices\"\"\"\n",
    "x_all = (x_0, x_1, x_2)\n",
    "\n",
    "conv_order = 5\n",
    "in_channels_all = (x_0.shape[-1], x_1.shape[-1], x_2.shape[-1])\n",
    "intermediate_channels_all = (4, 4, 4)\n",
    "out_channels_all = intermediate_channels_all\n",
    "num_layers = 2\n",
    "\n",
    "laplacian_all = (\n",
    "    laplacian_0,\n",
    "    laplacian_down_1,\n",
    "    laplacian_up_1,\n",
    "    laplacian_down_2,\n",
    "    laplacian_up_2,\n",
    ")\n",
    "\n",
    "incidence_all = (incidence_1, incidence_2)\n",
    "\n",
    "model = SCCNN(\n",
    "    in_channels_all=in_channels_all,\n",
    "    intermediate_channels_all=intermediate_channels_all,\n",
    "    out_channels_all=out_channels_all,\n",
    "    conv_order=conv_order,\n",
    "    sc_order=max_rank,\n",
    "    n_layers=num_layers,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 20\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x_all, laplacian_all, incidence_all)\n",
    "    loss = torch.nn.functional.binary_cross_entropy(\n",
    "        y_hat[: len(y_train)].float(), y_train.float()\n",
    "    )\n",
    "    epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred = torch.where(y_hat > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    accuracy = (y_pred[-len(y_train) :] == y_train).all(dim=1).float().mean().item()\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {accuracy:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat_test = model(x_all, laplacian_all, incidence_all)\n",
    "            y_pred_test = torch.where(\n",
    "                y_hat_test > 0.5, torch.tensor(1), torch.tensor(0)\n",
    "            )\n",
    "            test_accuracy = (\n",
    "                torch.eq(y_pred_test[-len(y_test) :], y_test)\n",
    "                .all(dim=1)\n",
    "                .float()\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
