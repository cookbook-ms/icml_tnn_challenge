{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets.graph as graph\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "### Import Karate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4\n",
      "maximal simple order: 4\n"
     ]
    }
   ],
   "source": [
    "dataset = graph.karate_club(complex_type=\"simplicial\")\n",
    "print(dataset)\n",
    "\n",
    "# Maximal simplex order\n",
    "max_rank = dataset.dim\n",
    "print(\"maximal simple order:\", max_rank)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neighborhood Strctures\n",
    "Get incidence matrices and Hodge Laplacians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The incidence matrix B1 has shape: torch.Size([34, 78]).\n",
      "The incidence matrix B2 has shape: torch.Size([78, 45]).\n"
     ]
    }
   ],
   "source": [
    "incidence_1 = dataset.incidence_matrix(rank=1)\n",
    "incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "incidence_2 = dataset.incidence_matrix(rank=2)\n",
    "incidence_2 = torch.from_numpy(incidence_2.todense()).to_sparse()\n",
    "print(f\"The incidence matrix B1 has shape: {incidence_1.shape}.\")\n",
    "print(f\"The incidence matrix B2 has shape: {incidence_2.shape}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Hodge Laplacians\n",
    "In the original paper, the weighted versions of the Hodge Laplacians are used. However, the current TOPONETX package does not provide this weighting feature yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_0 = dataset.hodge_laplacian_matrix(rank=0, weight=True)\n",
    "laplacian_down_1 = dataset.down_laplacian_matrix(rank=1, weight=True)\n",
    "laplacian_up_1 = dataset.up_laplacian_matrix(rank=1, weight=True)\n",
    "laplacian_down_2 = dataset.down_laplacian_matrix(rank=2, weight=True)\n",
    "laplacian_up_2 = dataset.up_laplacian_matrix(rank=2, weight=True)\n",
    "\n",
    "laplacian_0 = torch.from_numpy(laplacian_0.todense()).to_sparse()\n",
    "laplacian_down_1 = torch.from_numpy(laplacian_down_1.todense()).to_sparse()\n",
    "laplacian_up_1 = torch.from_numpy(laplacian_up_1.todense()).to_sparse()\n",
    "laplacian_down_2 = torch.from_numpy(laplacian_down_2.todense()).to_sparse()\n",
    "laplacian_up_2 = torch.from_numpy(laplacian_up_2.todense()).to_sparse()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import signals\n",
    "#### Depending on the task, we can perform learning on any order of the simplices. Thus, the corresponding order of the input can be selected. \n",
    "\n",
    "For example, performing learning on the edges, we use the input on edges $\\mathbf{x}_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 nodes with features of dimension 2.\n",
      "There are 78 edges with features of dimension 2.\n",
      "There are 45 faces with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "x_0 = []\n",
    "for _, v in dataset.get_simplex_attributes(\"node_feat\").items():\n",
    "    x_0.append(v)\n",
    "x_0 = torch.tensor(np.stack(x_0))\n",
    "channels_nodes = x_0.shape[-1]\n",
    "x_1 = []\n",
    "for k, v in dataset.get_simplex_attributes(\"edge_feat\").items():\n",
    "    x_1.append(v)\n",
    "x_1 = np.stack(x_1)\n",
    "chennel_edges = x_1.shape[-1]\n",
    "x_2 = []\n",
    "for k, v in dataset.get_simplex_attributes(\"face_feat\").items():\n",
    "    x_2.append(v)\n",
    "x_2 = np.stack(x_2)\n",
    "channel_faces = x_2.shape[-1]\n",
    "print(f\"There are {x_0.shape[0]} nodes with features of dimension {x_0.shape[1]}.\")\n",
    "print(f\"There are {x_1.shape[0]} edges with features of dimension {x_1.shape[1]}.\")\n",
    "print(f\"There are {x_2.shape[0]} faces with features of dimension {x_2.shape[1]}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to select the features on certain order of simplices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A function to obtain features based on the input: rank\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_simplicial_features(dataset, rank):\n",
    "    if rank == 0:\n",
    "        which_feat = \"node_feat\"\n",
    "    elif rank == 1:\n",
    "        which_feat = \"edge_feat\"\n",
    "    elif rank == 2:\n",
    "        which_feat = \"face_feat\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"input dimension must be 0, 1 or 2, because features are supported on nodes, edges and faces\"\n",
    "        )\n",
    "\n",
    "    x = []\n",
    "    for _, v in dataset.get_simplex_attributes(which_feat).items():\n",
    "        x.append(v)\n",
    "\n",
    "    x = torch.tensor(np.stack(x))\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define binary labels and Prepare the training-testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "y_true = np.zeros((34, 2))\n",
    "y_true[:, 0] = y\n",
    "y_true[:, 1] = 1 - y\n",
    "y_test = y_true[-4:]\n",
    "y_train = y_true[:30]\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SCNN\n",
    "Use the SCNNLayer classm we create a neural network with stacked layers. A final linear layer produces an output with shape $n_{\\rm{nodes}}\\times 2$, so we can compare with the binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topomodelx.nn.simplicial.scnn_layer import SCNNLayer\n",
    "\n",
    "\n",
    "class SCNN(torch.nn.Module):\n",
    "    \"\"\"Simplicial convolutional neural network implementation for binary node classification.\n",
    "\n",
    "    Note: At the last layer, we obtain the output on simplcies, e.g., edges.\n",
    "    To perform the node classification task for this challenge, we consider a projection step via the incidence matrix B_1 which obtains the node labels from the edge output, which was also done in \"T Mitchell Roddenberry, Nicholas Glaze and Santiago Segarra. Principled simplicial neural networks for trajectory prediction. International Conference on Machine Learning. 2021\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels: int\n",
    "        Dimension of input features\n",
    "    intermediate_channels: int\n",
    "        Dimension of features of intermediate layers\n",
    "    out_channels: int\n",
    "        Dimension of output features\n",
    "    conv_order_down: int\n",
    "        Order of lower convolution\n",
    "    conv_order_up: int\n",
    "        Order of upper convolution\n",
    "    n_layers: int\n",
    "        Numer of layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        conv_order_down,\n",
    "        conv_order_up,\n",
    "        aggr_norm=False,\n",
    "        update_func=None,\n",
    "        n_layers=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # First layer -- initial layer has the in_channels as input, and inter_channels as the output\n",
    "        layers = [\n",
    "            SCNNLayer(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=intermediate_channels,\n",
    "                conv_order_down=conv_order_down,\n",
    "                conv_order_up=conv_order_up,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(\n",
    "                SCNNLayer(\n",
    "                    in_channels=intermediate_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    conv_order_down=conv_order_down,\n",
    "                    conv_order_up=conv_order_up,\n",
    "                    aggr_norm=aggr_norm,\n",
    "                    update_func=update_func,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.linear = torch.nn.Linear(out_channels, 2)\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, laplacian_down, laplacian_up, incidence_1):\n",
    "        \"\"\"Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x: tensor\n",
    "            shape = [n_simplices, channels]\n",
    "            node/edge/face features\n",
    "\n",
    "        laplacian: tensor\n",
    "            shape = [n_simplices,n_simplices]\n",
    "            For node features, laplacian_down = None\n",
    "\n",
    "        incidence_1: tensor\n",
    "            order 1 incidence matrix\n",
    "            shape = [n_edges, n_nodes]\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, laplacian_down, laplacian_up)\n",
    "        \"\"\"\n",
    "        Project the output from edges to nodes \n",
    "        incidence_1 @ x\n",
    "        \"\"\"\n",
    "        logits = self.linear(incidence_1 @ x)\n",
    "        return torch.softmax(logits, dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the SCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN(\n",
      "  (linear): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x SCNNLayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Select the simplex order, i.e., on which level of simplices the learning will be performed \n",
    "\"\"\"\n",
    "rank = 1  # simplex level\n",
    "conv_order_down = 2\n",
    "conv_order_up = 2\n",
    "x = get_simplicial_features(dataset, rank)\n",
    "channels_x = x.shape[-1]\n",
    "if rank == 0:\n",
    "    laplacian_down = None\n",
    "    laplacian_up = laplacian_0  # the graph laplacian\n",
    "    conv_order_down = 0\n",
    "elif rank == 1:\n",
    "    laplacian_down = laplacian_down_1\n",
    "    laplacian_up = laplacian_up_1\n",
    "elif rank == 2:\n",
    "    laplacian_down = laplacian_down_2\n",
    "    laplacian_up = laplacian_up_2\n",
    "else:\n",
    "    raise ValueError(f\"Rank must be not larger than 2 on this dataset\")\n",
    "\n",
    "intermediate_channels = 16\n",
    "out_channels = intermediate_channels\n",
    "\n",
    "num_layers = 2\n",
    "model = SCNN(\n",
    "    in_channels=channels_nodes,\n",
    "    intermediate_channels=intermediate_channels,\n",
    "    out_channels=out_channels,\n",
    "    conv_order_down=conv_order_down,\n",
    "    conv_order_up=conv_order_up,\n",
    "    n_layers=num_layers,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 2])\n",
      "Epoch: 1 loss: 0.7092 Train_acc: 0.5333\n",
      "torch.Size([34, 2])\n",
      "Epoch: 2 loss: 0.7107 Train_acc: 0.5333\n",
      "Test_acc: 0.2500\n",
      "torch.Size([34, 2])\n",
      "Epoch: 3 loss: 0.7102 Train_acc: 0.5333\n",
      "torch.Size([34, 2])\n",
      "Epoch: 4 loss: 0.7065 Train_acc: 0.5333\n",
      "Test_acc: 0.2500\n",
      "torch.Size([34, 2])\n",
      "Epoch: 5 loss: 0.7045 Train_acc: 0.5667\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 5\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat = model(x, laplacian_down, laplacian_up, incidence_1)\n",
    "    print(y_hat.shape)\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_hat[: len(y_train)].float(), y_train.float()\n",
    "    )\n",
    "    epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred = torch.where(y_hat > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    accuracy = (y_pred[-len(y_train) :] == y_train).all(dim=1).float().mean().item()\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {accuracy:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat_test = model(x, laplacian_down, laplacian_up, incidence_1)\n",
    "            y_pred_test = torch.where(\n",
    "                y_hat_test > 0.5, torch.tensor(1), torch.tensor(0)\n",
    "            )\n",
    "            test_accuracy = (\n",
    "                torch.eq(y_pred_test[-len(y_test) :], y_test)\n",
    "                .all(dim=1)\n",
    "                .float()\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
