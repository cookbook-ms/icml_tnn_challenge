{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a SCCNN\n",
    "\n",
    "In this notebook, we will create and train a High Skip Network in the simplicial complex domain, as proposed in the paper by [Yang et. al : Convolutional Learning on Simplicial Complexes (2023)](https://arxiv.org/abs/2301.11163). \n",
    "\n",
    "We train the model to perform binary node classification using the KarateClub benchmark dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets as datasets\n",
    "\n",
    "from topomodelx.nn.simplicial.scnn_layer import SCNNLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "We must first lift our graph dataset into the simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    " \n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider using edge features for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_0 = x_0s[-1].shape[1]\n",
    "in_channels_1 = x_1s[-1].shape[1]\n",
    "in_channels_2 = x_2s[-1].shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank = 2 # the order of the SC is two \n",
    "incidence_1_list = []\n",
    "incidence_2_list = []\n",
    "\n",
    "laplacian_0_list = []\n",
    "laplacian_down_1_list = []\n",
    "laplacian_up_1_list = []\n",
    "laplacian_2_list = []\n",
    " \n",
    "for simplex in simplexes: \n",
    "    incidence_1 = simplex.incidence_matrix(rank=1)\n",
    "    incidence_2 = simplex.incidence_matrix(rank=2)\n",
    "    laplacian_0 = simplex.hodge_laplacian_matrix(rank=0,weight=True)\n",
    "    laplacian_down_1 = simplex.down_laplacian_matrix(rank=1,weight=True)\n",
    "    laplacian_up_1 = simplex.up_laplacian_matrix(rank=1,weight=True)\n",
    "    laplacian_2 = simplex.hodge_laplacian_matrix(rank=2,weight=True)\n",
    "    \n",
    "    incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "    incidence_2 = torch.from_numpy(incidence_2.todense()).to_sparse()\n",
    "    laplacian_0 = torch.from_numpy(laplacian_0.todense()).to_sparse()\n",
    "    laplacian_down_1 = torch.from_numpy(laplacian_down_1.todense()).to_sparse()\n",
    "    laplacian_up_1 = torch.from_numpy(laplacian_up_1.todense()).to_sparse()\n",
    "    laplacian_2 = torch.from_numpy(laplacian_2.todense()).to_sparse()\n",
    "    \n",
    "    incidence_1_list.append(incidence_1)\n",
    "    incidence_2_list.append(incidence_2)\n",
    "    laplacian_0_list.append(laplacian_0)\n",
    "    laplacian_down_1_list.append(laplacian_down_1)\n",
    "    laplacian_up_1_list.append(laplacian_up_1)\n",
    "    laplacian_2_list.append(laplacian_2)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SCCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNN(torch.nn.Module):\n",
    "    \"\"\"SCCNN implementation for binary node classification \n",
    "    Note: In this task, we direcly consider the finaly output on the nodes, which is passed by a linear layer, as the label output. \n",
    "\n",
    "    Parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, intermediate_channels,out_channels, conv_order_down, conv_order_up, aggr_norm=False,update_func=\"sigmoid\", n_layers=2):\n",
    "        super().__init__()\n",
    "        # first layer \n",
    "        # self.in_linear_1 = torch.nn.Linear(in_channels_all[1],intermediate_channels_all[1]) \n",
    "        layers = [SCNNLayer(in_channels=in_channels,out_channels=intermediate_channels,conv_order_down=conv_order_down,conv_order_up=conv_order_up)]\n",
    "        for _ in range(n_layers-1):\n",
    "            layers.append(\n",
    "                SCNNLayer(in_channels=intermediate_channels,out_channels=out_channels,conv_order_down=conv_order_down,conv_order_up=conv_order_up,aggr_norm=aggr_norm,update_func=update_func)\n",
    "            )\n",
    "            \n",
    "        self.layers = layers    \n",
    "        self.out_linear = torch.nn.Linear(out_channels,1)\n",
    "\n",
    "\n",
    "    def forward(self,x,laplacian_down, laplacian_up):\n",
    "        \"\"\"Forward computation. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,laplacian_down,laplacian_up)\n",
    "        \n",
    "        pooled_x = torch.max(x,dim=0)[0]\n",
    "        y = torch.sigmoid(self.out_linear(pooled_x))[0]\n",
    " \n",
    "        return y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1 # simplex level \n",
    "conv_order_down = 2\n",
    "conv_order_up = 2\n",
    "intermediate_channels = 4\n",
    "out_channels = intermediate_channels\n",
    "num_layers = 2\n",
    "\n",
    "# select the simplex level\n",
    "if rank == 0: \n",
    "    laplacian_down = None\n",
    "    laplacian_up = laplacian_0_list # the graph laplacian \n",
    "    conv_order_down = 0\n",
    "    x = x_0s\n",
    "    in_channels = in_channels_0\n",
    "elif rank == 1:\n",
    "    laplacian_down = laplacian_down_1_list\n",
    "    laplacian_up = laplacian_up_1_list\n",
    "    x = x_1s\n",
    "    in_channels = in_channels_1\n",
    "elif rank == 2:\n",
    "    laplacian_down = laplacian_2_list\n",
    "    laplacian_up = None \n",
    "    x = x_2s\n",
    "    in_channels = in_channels_2 \n",
    "else: \n",
    "    raise ValueError(\n",
    "        f\"Rank must be not larger than 2 on this dataset\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SCNN(in_channels = in_channels,intermediate_channels = intermediate_channels,out_channels = out_channels, conv_order_down=conv_order_down,conv_order_up=conv_order_up,n_layers=num_layers\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_train, x_test = train_test_split(x, test_size=test_size, shuffle=False)\n",
    "\n",
    "laplacian_down_train, laplacian_down_test = train_test_split(laplacian_down, test_size=test_size, shuffle=False)\n",
    "laplacian_up_train, laplacian_up_test = train_test_split(laplacian_up, test_size=test_size, shuffle=False)\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/mmaosheng/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:243: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  if not is_compiling() and torch.has_cuda and torch.cuda.is_available():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 279.5853\n",
      "Test_loss: 531.4301\n",
      "Epoch: 2 loss: 275.5110\n",
      "Test_loss: 529.9162\n",
      "Epoch: 3 loss: 275.0299\n",
      "Test_loss: 529.5111\n",
      "Epoch: 4 loss: 274.8655\n",
      "Test_loss: 529.3348\n",
      "Epoch: 5 loss: 274.7860\n",
      "Test_loss: 529.2397\n"
     ]
    }
   ],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 5\n",
    "\n",
    "# select which feature to use for labeling\n",
    "simplex_order_select = 1\n",
    "\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x, laplacian_down, laplacian_up, y in zip(x_train, laplacian_down_train, laplacian_up_train, y_train):\n",
    "\n",
    "        x = torch.tensor(x,dtype=torch.float)\n",
    "        y = torch.tensor(y,dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(x, laplacian_down, laplacian_up)\n",
    "\n",
    "        # print(y_hat.shape)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x, laplacian_down, laplacian_up, y in zip(x_test, laplacian_down_test, laplacian_up_test, y_test):\n",
    "    \n",
    "                x = torch.tensor(x,dtype=torch.float)\n",
    "                y = torch.tensor(y,dtype=torch.float)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                y_hat = model(x, laplacian_down, laplacian_up)\n",
    "\n",
    "                    \n",
    "                loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
