{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a SCCNN\n",
    "\n",
    "In this notebook, we will create and train a High Skip Network in the simplicial complex domain, as proposed in the paper by [Yang et. al : Convolutional Learning on Simplicial Complexes (2023)](https://arxiv.org/abs/2301.11163). \n",
    "\n",
    "We train the model to perform binary node classification using the KarateClub benchmark dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets as datasets\n",
    "\n",
    "from topomodelx.nn.simplicial.sccnn_layer import SCCNNLayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "We must first lift our graph dataset into the simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    " \n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10, 7)\n"
     ]
    }
   ],
   "source": [
    "in_channels_0 = x_0s[-1].shape[1]\n",
    "in_channels_1 = x_1s[-1].shape[1]\n",
    "in_channels_2 = x_2s[-1].shape[1]\n",
    "\n",
    "in_channels_all = (in_channels_0,in_channels_1,in_channels_2)\n",
    "print(in_channels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank = 2 # the order of the SC is two \n",
    "incidence_1_list = []\n",
    "incidence_2_list = []\n",
    "\n",
    "laplacian_0_list = []\n",
    "laplacian_down_1_list = []\n",
    "laplacian_up_1_list = []\n",
    "laplacian_2_list = []\n",
    " \n",
    "for simplex in simplexes: \n",
    "    incidence_1 = simplex.incidence_matrix(rank=1)\n",
    "    incidence_2 = simplex.incidence_matrix(rank=2)\n",
    "    laplacian_0 = simplex.hodge_laplacian_matrix(rank=0,weight=True)\n",
    "    laplacian_down_1 = simplex.down_laplacian_matrix(rank=1,weight=True)\n",
    "    laplacian_up_1 = simplex.up_laplacian_matrix(rank=1,weight=True)\n",
    "    laplacian_2 = simplex.hodge_laplacian_matrix(rank=2,weight=True)\n",
    "    \n",
    "    incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "    incidence_2 = torch.from_numpy(incidence_2.todense()).to_sparse()\n",
    "    laplacian_0 = torch.from_numpy(laplacian_0.todense()).to_sparse()\n",
    "    laplacian_down_1 = torch.from_numpy(laplacian_down_1.todense()).to_sparse()\n",
    "    laplacian_up_1 = torch.from_numpy(laplacian_up_1.todense()).to_sparse()\n",
    "    laplacian_2 = torch.from_numpy(laplacian_2.todense()).to_sparse()\n",
    "    \n",
    "    incidence_1_list.append(incidence_1)\n",
    "    incidence_2_list.append(incidence_2)\n",
    "    laplacian_0_list.append(laplacian_0)\n",
    "    laplacian_down_1_list.append(laplacian_down_1)\n",
    "    laplacian_up_1_list.append(laplacian_up_1)\n",
    "    laplacian_2_list.append(laplacian_2)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SCCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCCNN(torch.nn.Module):\n",
    "    \"\"\"SCCNN implementation for binary node classification \n",
    "    Note: In this task, we direcly consider the finaly output on the nodes, which is passed by a linear layer, as the label output. \n",
    "\n",
    "    Parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels_all, intermediate_channels_all,out_channels_all, conv_order, sc_order, aggr_norm=False,update_func=\"sigmoid\",n_layers=2):\n",
    "        super().__init__()\n",
    "        # first layer \n",
    "        # layers = [SCCNNLayer(in_channels=in_channels_all,out_channels=intermediate_channels_all,conv_order=conv_order,sc_order=sc_order,aggr_norm=aggr_norm,update_func=update_func)]\n",
    "        self.in_linear_0 = torch.nn.Linear(in_channels_all[0],intermediate_channels_all[0])\n",
    "        self.in_linear_1 = torch.nn.Linear(in_channels_all[1],intermediate_channels_all[1])\n",
    "        self.in_linear_2 = torch.nn.Linear(in_channels_all[2],intermediate_channels_all[2])\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                SCCNNLayer(in_channels=intermediate_channels_all,out_channels=out_channels_all,conv_order=conv_order,sc_order=sc_order,aggr_norm=aggr_norm,update_func=update_func)\n",
    "            )\n",
    "            \n",
    "        self.layers = layers    \n",
    "        out_channels_0, out_channels_1, out_channels_2 = out_channels_all\n",
    "        self.out_linear_0 = torch.nn.Linear(out_channels_0,1)\n",
    "        self.out_linear_1 = torch.nn.Linear(out_channels_1,1)\n",
    "        self.out_linear_2 = torch.nn.Linear(out_channels_2,1)\n",
    "        \n",
    "\n",
    "    def forward(self,x_all,laplacian_all,incidence_all):\n",
    "        \"\"\"Forward computation. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        x_0, x_1, x_2 = x_all\n",
    "        in_x_0 = self.in_linear_0(x_0)\n",
    "        in_x_1 = self.in_linear_1(x_1)\n",
    "        in_x_2 = self.in_linear_2(x_2)\n",
    "        x_all = (in_x_0,in_x_1,in_x_2)\n",
    "        for layer in self.layers:\n",
    "            x_all = layer(x_all,laplacian_all,incidence_all)\n",
    "        \n",
    "        \"\"\"\n",
    "        We pass the output on the nodes, edges and triangles to a pooling layer then a linear layer and use that for labels\n",
    "        \"\"\"\n",
    "        x_0, x_1, x_2 = x_all \n",
    "\n",
    "        pooled_x_0 = torch.max(x_0,dim=0)[0]    \n",
    "        pooled_x_1 = torch.max(x_1,dim=0)[0]\n",
    "        pooled_x_2 = torch.max(x_2,dim=0)[0]    \n",
    "        y_0 = torch.sigmoid(self.out_linear_0(pooled_x_0))[0]\n",
    "        y_1 = torch.sigmoid(self.out_linear_1(pooled_x_1))[0]\n",
    "        y_2 = torch.sigmoid(self.out_linear_2(pooled_x_2))[0]\n",
    "        return y_0, y_1, y_2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv_order = 3\n",
    "intermediate_channels_all = (4,4,4)\n",
    "out_channels_all = intermediate_channels_all\n",
    "num_layers = 2\n",
    "\n",
    "model = SCCNN(in_channels_all=in_channels_all,intermediate_channels_all=intermediate_channels_all,out_channels_all=out_channels_all,conv_order=conv_order,sc_order=max_rank,n_layers=num_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "x_2_train, x_2_test = train_test_split(x_2s, test_size=test_size, shuffle=False)\n",
    "\n",
    "incidence_1_train, incidence_1_test = train_test_split(\n",
    "    incidence_1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence_2_train, incidence_2_test = train_test_split(incidence_2_list, test_size=test_size, shuffle=False)\n",
    "laplacian_0_train, laplacian_0_test = train_test_split(laplacian_0_list, test_size=test_size, shuffle=False)\n",
    "laplacian_down_1_train, laplacian_down_1_test = train_test_split(laplacian_down_1_list, test_size=test_size, shuffle=False)\n",
    "laplacian_up_1_train, laplacian_up_1_test = train_test_split(laplacian_up_1_list, test_size=test_size, shuffle=False)\n",
    "laplacian_2_train, laplacian_2_test = train_test_split(laplacian_2_list, test_size=test_size, shuffle=False)\n",
    "\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 277.6436\n",
      "Test_loss: 530.5171\n",
      "Epoch: 2 loss: 275.1914\n",
      "Test_loss: 529.6067\n",
      "Epoch: 3 loss: 274.8917\n",
      "Test_loss: 529.3450\n",
      "Epoch: 4 loss: 274.7841\n",
      "Test_loss: 529.2281\n",
      "Epoch: 5 loss: 274.7310\n",
      "Test_loss: 529.1642\n"
     ]
    }
   ],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 5\n",
    "\n",
    "# select which feature to use for labeling\n",
    "simplex_order_select = 1\n",
    "\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, x_1, x_2, incidence_1, incidence_2, laplacian_0, laplacian_down_1, laplacian_up_1, laplacian_2, y in zip(x_0_train, x_1_train, x_2_train, incidence_1_train, incidence_2_train, laplacian_0_train, laplacian_down_1_train, laplacian_up_1_train, laplacian_2_train, y_train):\n",
    "        \n",
    "        x_0 = torch.tensor(x_0)\n",
    "        x_1 = torch.tensor(x_1)\n",
    "        x_2 = torch.tensor(x_2)\n",
    "        y = torch.tensor(y,dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        x_all = (x_0.float(),x_1.float(),x_2.float())\n",
    "        laplacian_all = (laplacian_0, laplacian_down_1, laplacian_up_1, laplacian_2)\n",
    "        incidence_all = (incidence_1, incidence_2)\n",
    "\n",
    "        y_hat = model(x_all, laplacian_all, incidence_all)\n",
    "\n",
    "        # print(y_hat.shape)\n",
    "        loss = loss_fn(y_hat[simplex_order_select], y)\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_0, x_1, x_2, incidence_1, incidence_2, laplacian_0, laplacian_down_1, laplacian_up_1, laplacian_2, y in zip(x_0_test, x_1_test, x_2_test, incidence_1_test, incidence_2_test, laplacian_0_test, laplacian_down_1_test, laplacian_up_1_test, laplacian_2_test, y_test):\n",
    "    \n",
    "                x_0 = torch.tensor(x_0)\n",
    "                x_1 = torch.tensor(x_1)\n",
    "                x_2 = torch.tensor(x_2)\n",
    "                y = torch.tensor(y,dtype=torch.float)\n",
    "                optimizer.zero_grad()\n",
    "                x_all = (x_0.float(),x_1.float(),x_2.float())\n",
    "                laplacian_all = (laplacian_0, laplacian_down_1, laplacian_up_1, laplacian_2)\n",
    "                incidence_all = (incidence_1, incidence_2)\n",
    "\n",
    "                y_hat = model(x_all, laplacian_all, incidence_all)\n",
    "\n",
    "                    \n",
    "                loss = loss_fn(y_hat[simplex_order_select], y)\n",
    "            print(f\"Test_loss: {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
